{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa40fba9-4aa0-40a6-a5f5-33c7f86b5a63",
   "metadata": {},
   "source": [
    "# 00 - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe7afc-3bcd-4467-bd57-d05738fb990c",
   "metadata": {},
   "source": [
    "This lab has been tested in Amazon SageMaker AI Studio using JupyterLab and the SageMaker Distribution 2.4.1 container image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdacfec-1991-486c-96e7-18a0489b636e",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to this hands-on workshop on building a credit risk assessment model using Amazon SageMaker!\n",
    "\n",
    "\n",
    "In this first notebook, you'll set up your development environment and prepare a dataset that will serve as the foundation for your machine learning use case.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> Use Case: You are working for Octank Bank and you want to develop a classification model that predicts whether a customer presents credit risk. \n",
    "</div> \n",
    "\n",
    "\n",
    "**Business Context**:\n",
    "Credit risk assessment is a critical operation in the financial sector that helps determine the likelihood of borrowers repaying their loans. Accurate risk prediction enables financial institutions to:\n",
    "- Make sound lending decisions\n",
    "- Reduce default rates and potential losses\n",
    "- Optimize interest rates based on risk profiles\n",
    "- Comply with regulatory requirements for risk management\n",
    "\n",
    "\n",
    "    \n",
    "**Your Task**:\n",
    "As a data scientist at Octank Bank, you're tasked with developing a classification model to predict whether a customer presents a credit risk. Throughout this workshop series, you'll learn how to:\n",
    "- Set up your SageMaker environment\n",
    "- Prepare and analyze your data\n",
    "- Train and deploy a machine learning model using Amazon SageMaker Studio\n",
    "- Evaluate model performance and interpret results\n",
    "\n",
    "**Prerequisites:**\n",
    "- Basic understanding of Python\n",
    "- Familiarity with machine learning concepts\n",
    "\n",
    "What You'll Learn in This Notebook:\n",
    "1. Setting up your SageMaker environment\n",
    "2. Loading and exploring the credit risk dataset\n",
    "3. Performing initial data preprocessing\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d62c824-3fd3-40e8-8b58-f42da79ccec7",
   "metadata": {},
   "source": [
    "## About the Dataset:  \n",
    "\n",
    "The [South German Credit](https://archive.ics.uci.edu/ml/datasets/South+German+Credit+%28UPDATE%29#) dataset is an industry standard benchmark dataset in the field of credit scoring. It contains information about 1,000 loan applicants, including:\n",
    "\n",
    "- Credit history\n",
    "- Loan purpose\n",
    "- Loan amount\n",
    "- Employment duration\n",
    "- Personal status and gender\n",
    "- Other debtors/guarantors\n",
    "- Property ownership\n",
    "- Other installment plans\n",
    "- Housing situation\n",
    "- Job information\n",
    "\n",
    "The target variable _credit_risk_ indicates whether a customer is considered a good or bad credit risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a43f64-f992-4b98-b120-bf2f8ebc5521",
   "metadata": {},
   "source": [
    "## 1. Setting Up Your ML Environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d920cbac-3696-4cd4-838c-72f3461d9ba9",
   "metadata": {},
   "source": [
    "First, let's prepare our development environment and download the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b8a65",
   "metadata": {},
   "source": [
    "### 1.1 Install required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b1d3b2-2543-4475-b568-15cd52a3e005",
   "metadata": {},
   "source": [
    "In Amazon SageMaker AI Studio, the JupyterLab application comes with the [SageMaker Distribution](https://github.com/aws/sagemaker-distribution) image. The distribution image has popular packages, such as PyTorch, TensorFlow, Keras, NumPy, Pandas, Scikit-learn pre-installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6dd06d-6d32-4272-b333-a5adb3ee94dc",
   "metadata": {},
   "source": [
    "Let's install some additional packages that are required for this lab and set-up the development environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937e30f-816c-4e54-88ec-867faf051fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef30aec7-e1bf-44fe-96d2-f0847a26568a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Important:</b> Once the previous step is complete, make sure you restart the kernel before proceeding.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf86a5",
   "metadata": {},
   "source": [
    "### 1.2 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa39930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4763bea-6fed-4bf3-980c-7b4557962408",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Download and Prepare Data\n",
    "In the following section, you download the dataset and perform some initial pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde30f91-1afd-4378-8394-bcd247a0de76",
   "metadata": {},
   "source": [
    "### 2.1 Download dataset\n",
    "\n",
    "Download the dataset from the SageMaker sample files repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b872c02-c2d0-44f5-bd59-06eede22b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "S3Downloader.download(\n",
    "    \"s3://sagemaker-sample-files/datasets/tabular/uci_statlog_german_credit_data/SouthGermanCredit.asc\",\n",
    "    \"data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa50b5fe",
   "metadata": {},
   "source": [
    "### 2.2 Split the data into training and test data sets\n",
    "The code below follows standard data preparation steps, setting up the data for model training and evaluation. The original dataset is split into training and test using a 80-20 split. It also remove missing values, sets a random seed for reproduciblility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce39f68-6e63-425c-b281-d172c6776fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Column names for the data set\n",
    "credit_columns = [\n",
    "    \"status\",\n",
    "    \"duration\",\n",
    "    \"credit_history\",\n",
    "    \"purpose\",\n",
    "    \"amount\",\n",
    "    \"savings\",\n",
    "    \"employment_duration\",\n",
    "    \"installment_rate\",\n",
    "    \"personal_status_sex\",\n",
    "    \"other_debtors\",\n",
    "    \"present_residence\",\n",
    "    \"property\",\n",
    "    \"age\",\n",
    "    \"other_installment_plans\",\n",
    "    \"housing\",\n",
    "    \"number_credits\",\n",
    "    \"job\",\n",
    "    \"people_liable\",\n",
    "    \"telephone\",\n",
    "    \"foreign_worker\",\n",
    "    \"credit_risk\",\n",
    "]\n",
    "\n",
    "# Read the CSV data into a pandas DataFrame\n",
    "data = pd.read_csv(\n",
    "    \"data/SouthGermanCredit.asc\",\n",
    "    names=credit_columns,\n",
    "    header=0,\n",
    "    sep=r\" \",\n",
    "    engine=\"python\",\n",
    "    na_values=\"?\",\n",
    ").dropna()\n",
    "\n",
    "# Assuming the last column is your label/target\n",
    "# First, let's separate features (X) from the label (y)\n",
    "X = data.iloc[:, :-1]  # All columns except the last one\n",
    "y = data.iloc[:, -1]   # Only the last column\n",
    "\n",
    "# Now, split the data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42  # 20% test data, set random_state for reproducibility\n",
    ")\n",
    "\n",
    "# To verify the shapes of your resulting datasets\n",
    "print(f\"Original data shape: {data.shape}\")\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4ca1b4-3777-4e37-8b9b-a54a50769fe3",
   "metadata": {},
   "source": [
    "### 2.3 Save the data in your JupyterLab space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e2c3d-9648-4eff-9ff6-21d4ba94f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(directory_path):\n",
    "    try:\n",
    "        if os.path.exists(directory_path):\n",
    "            print(f\"The '{directory_path}' directory already exists.\")\n",
    "        else:\n",
    "            os.makedirs(directory_path)\n",
    "            print(f\"Created '{directory_path}' directory successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f95700-55f6-4985-b550-5cf24f540450",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"./input\"\n",
    "create_directory(input_dir)\n",
    "\n",
    "output_dir = \"./output\"\n",
    "create_directory(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32e95d-006c-4b13-befa-4ce7db38a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "train_data_path=f\"{input_dir}/train_data.csv\"\n",
    "test_data_path=f\"{input_dir}/test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_path, index=False)\n",
    "test_data.to_csv(test_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff565bd0-5cf1-45e9-a264-8eb9e0958eb4",
   "metadata": {},
   "source": [
    "You can also store the above variables to make them available across different notebook sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6748413c-e6a9-4adb-8899-b2c8398ec55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store train_data_path test_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c612d4a-4161-4acd-921c-345cbbc66053",
   "metadata": {},
   "source": [
    "### 2.4 Upload the data to the default SageMaker S3 bucket for future use\n",
    "Finally, let's also upload the datasets to Amazon S3 so that they are available for subsequent notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57ca99-95e1-489c-8b7a-e6b45c28ce3d",
   "metadata": {},
   "source": [
    "When using Amazon SageMaker AI Studio, you have a default Amazon S3 bucket allocated for your SageMaker AI session. You can choose the default bucket or any bucket of your choice during development. For this lab, you will use the default bucket.\n",
    "\n",
    "Below you\n",
    "- create a SageMaker session and obtain the default bucket name.\n",
    "- define prefix as \"sm-ml-models\" to organize resources in S3.\n",
    "- extract the IAM execution role that provides SageMaker with the necessary AWS permissions for reading and writing data from/to S3 and performing SageMaker AI operations (which will be useful later) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c25a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name= sagemaker_session.default_bucket()  # Default SageMaker bucket\n",
    "model_prefix = \"sm-ml-models\"\n",
    "\n",
    "# Retrieve the IAM role for SageMaker\n",
    "role = sagemaker.get_execution_role()\n",
    "print (f\"Your Amazon SageMaker Execution role is: {role}\")\n",
    "\n",
    "%store bucket_name model_prefix role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f010e",
   "metadata": {},
   "source": [
    "Upload the training and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b80aa4-0ba7-42e7-9997-5ad68547a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the datasets in S3 for future use\n",
    "train_s3_url = sagemaker.Session().upload_data(\n",
    "    path=train_data_path,\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=f\"{model_prefix}/input\"\n",
    ")\n",
    "print(f\"Upload the dataset to {train_s3_url}\")\n",
    "\n",
    "test_s3_url = sagemaker.Session().upload_data(\n",
    "    path=test_data_path,\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=f\"{model_prefix}/input\"\n",
    ")\n",
    "print(f\"Upload the dataset to {test_s3_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bbb612-f0f4-4cdc-bb7d-321d08fb6f51",
   "metadata": {},
   "source": [
    "### Conclusion and Next Steps:\n",
    "- Your environment is ready\n",
    "- The data is prepared and stored\n",
    "- You're ready for Module 1!\n",
    "\n",
    "In Module 1, you'll use this foundation to build our first credit risk prediction model using XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b9c94-a59d-458e-ab35-d68a42136ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
