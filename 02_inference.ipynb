{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca297bb7-eee0-4121-b658-a3592f16f115",
   "metadata": {},
   "source": [
    "# 02 - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e833ba1-ba77-48da-9b3b-6ec8be95d735",
   "metadata": {},
   "source": [
    "You need to have the model artifacts in Amazon S3 to run this notebook. To train an XGboost model, **make sure you run the notebook from module 01 first before you proceed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d4394",
   "metadata": {},
   "source": [
    "## 1. Set up environment\n",
    "\n",
    "Restore variables from the `00_setup` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509fc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_data_path test_data_path\n",
    "%store -r bucket_name model_prefix\n",
    "%store -r model_artifact\n",
    "%store -r featurizer_model_dir\n",
    "%store -r role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a4704-bf26-45ef-9d4a-a75742fe0fb8",
   "metadata": {},
   "source": [
    "Import the necessary libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa4970-00ff-40a5-af84-ab51c3e04365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize SageMaker session and clients\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "runtime_client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "print(f\"Using region: {region}\")\n",
    "print(f\"Using model artifact: {model_artifact}\")\n",
    "print(f\"Using IAM role: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec29c2-370c-4b65-a661-9cbf212ca30f",
   "metadata": {},
   "source": [
    "## 2. Create a SageMaker Model from the S3 Artifact\n",
    "First, we will create a SageMaker model using the AWS builtin container and our model artifact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14cec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = time.strftime('%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name = f\"xgboost-realtime-{timestamp}\"\n",
    "endpoint_name = f\"xgboost-endpoint-{timestamp}\"\n",
    "\n",
    "image_uri= sagemaker.image_uris.retrieve(\n",
    "    framework='xgboost',\n",
    "    region=region,\n",
    "    version='1.7-1'\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_artifact,\n",
    "    role=role,\n",
    "    name=model_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "print(f\"Creating model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba892e-0e48-43fe-ad76-ed4cf2c8c8f1",
   "metadata": {},
   "source": [
    "## 3. Use the model for real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7323d942-a01a-411a-9331-3dee21babb5f",
   "metadata": {},
   "source": [
    "### 3.1 Deploy the model for real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a31bb4-5157-4480-8ff8-131d54014bd5",
   "metadata": {},
   "source": [
    "Now are ready to deploy the above model to a SageMaker real-time endpoint, making it available for inference requests.\n",
    "\n",
    "The deployment will create a single ml.m5.large instance that will host the model, and assign the endpoint a specific name stored in the endpoint_name variable. We also configure data serialization and deserialization formats - using CSV format for input data sent to the endpoint and JSON format for the responses returned.\n",
    "\n",
    "The predictor object that's created will serve as the client interface for making predictions against this endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f9ac89-38a2-4341-afc4-9c10661ffcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model to a real-time endpoint\n",
    "print(f\"Deploying model to endpoint: {endpoint_name}\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',  # Choose an appropriate instance type based on your needs\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "\n",
    "print(f\"Endpoint {endpoint_name} deployed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee74705",
   "metadata": {},
   "source": [
    "After the deployment is complete, view the model in the console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6977731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "sm_console_link = f\"https://{region}.console.aws.amazon.com/sagemaker/home?region={region}#/models\"\n",
    "display(HTML(f'<div></div>'))\n",
    "display(HTML(f'<a href=\"{sm_console_link}\" target=\"_blank\">View SageMaker Model</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa7973-91cf-4030-a626-cd978d0357b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEndpoint Information:\")\n",
    "print(f\"Endpoint Name: {endpoint_name}\")\n",
    "print(f\"Model Name: {model_name}\")\n",
    "\n",
    "%store model_name endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b85fd3f-b465-4ac5-ae4b-1a6c80ec4131",
   "metadata": {},
   "source": [
    "### 3.2 Pre-process the inference data\n",
    "Before we can send the new data to the model and generate predictions, we need to perform some data transformations to ensure it is in the format the ML model is expecting. For that, we will use the featurizer model we trained in notebook 01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b61ea66-d414-4034-bd2c-f195134f7c43",
   "metadata": {},
   "source": [
    "We will use the test dataset we created before to generate synthetic new data for 4 customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876e8845-3bb1-4184-8416-9b6b69b03354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "payload_df = pd.read_csv(\"./input/test_data.csv\")\n",
    "\n",
    "realtime_inference_test = payload_df.sample(n=4)\n",
    "\n",
    "realtime_inference_test.to_csv(\"inference.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb10e54-0838-4ef7-8ad7-28e5e94bcfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the samples data\n",
    "df1 = pd.read_csv('inference.csv')\n",
    "# Convert to CSV string\n",
    "csv_data = df1.to_csv(index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca38c146-0620-40ea-9365-329fb6ead52a",
   "metadata": {},
   "source": [
    "Next we pre-process the data of the 4 customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98cde4-4cc2-4365-a1ce-4d85d9c8b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import sklearn\n",
    "import joblib\n",
    "import mlflow\n",
    "from sagemaker.s3 import S3Uploader\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "\n",
    "def preprocess(df, featurizer_model):\n",
    "    try:\n",
    "        print(\"Performing one-hot encoding\")\n",
    "        categorical_cols = [\n",
    "            \"credit_history\",\n",
    "            \"purpose\",\n",
    "            \"personal_status_sex\",\n",
    "            \"other_debtors\",\n",
    "            \"property\",\n",
    "            \"other_installment_plans\",\n",
    "            \"housing\",\n",
    "            \"job\",\n",
    "            \"telephone\",\n",
    "            \"foreign_worker\",\n",
    "        ]\n",
    "        print(\"Preparing features and labels\")\n",
    "        X = df.drop(\"credit_risk\", axis=1,errors='ignore')\n",
    "\n",
    "        with (open(f\"{featurizer_model}/model.joblib\", \"rb\")) as openfile:\n",
    "            featurizer_model = joblib.load(openfile)\n",
    "            \n",
    "        print(\"Retrieving the scikit-learn transformer\",type(featurizer_model))\n",
    "        X_test = featurizer_model.transform(X)\n",
    "        print(f\"Train features shape after preprocessing: {X_test.shape}\")\n",
    "        \n",
    "        return X_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Exception in processing script: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd042978-06a0-4e6d-9f28-a965a4b16a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_input = preprocess(df1,featurizer_model_dir)\n",
    "print (payload_input)\n",
    "print(\"Number of samples in the payload:\",len(payload_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6948d0e-981f-4979-94dc-72198aa33396",
   "metadata": {},
   "source": [
    "### 3.3 Generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ea066-7a2e-4301-9b95-91bb8edfddd5",
   "metadata": {},
   "source": [
    "Now that the data is in the right format, we are ready to make predictions. The below code shows how to make real-time inference requests to your XGBoost model endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae64e2-bb46-478f-bd5e-7c9d83510abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "# Create predictor\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=CSVSerializer()\n",
    ")\n",
    "\n",
    "response = predictor.predict(payload_input,initial_args={'ContentType': 'text/csv'})\n",
    "print(\"result:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75869ecb-e0ad-4aa6-ad77-f39ea2ff0a14",
   "metadata": {},
   "source": [
    "## 4. Deploy the model for batch transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a10c7d-52ff-4b19-ae74-f0f867ac1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    local_path = tmpdirname + \"/batch_data.csv\"\n",
    "    df1 = pd.DataFrame(payload_input)\n",
    "    df1.to_csv(local_path, index=False)\n",
    "    input_data_path = sagemaker.Session().upload_data(\n",
    "        path=local_path,\n",
    "        bucket=bucket_name,\n",
    "        key_prefix=f\"{model_prefix}/input/batch-transform\"\n",
    "    )\n",
    " \n",
    "print(f\"batch transform input: {input_data_path}\")\n",
    "output_data_path = f\"s3://{bucket_name}/{model_prefix}/output/batch-transform/{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "print(f\"batch transform output: {output_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab1bd2-4052-423c-85f7-34c1be3c78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transformer object\n",
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=model.name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=output_data_path,\n",
    "    assemble_with='Line',\n",
    "    accept='text/csv',\n",
    "    strategy='SingleRecord'\n",
    ")\n",
    "\n",
    "# Start the batch transform job\n",
    "print(\"Starting batch transform job...\")\n",
    "transformer.transform(\n",
    "    data=input_data_path,\n",
    "    data_type='S3Prefix',\n",
    "    content_type='text/csv',\n",
    "    split_type='Line'\n",
    ")\n",
    "\n",
    "print(f\"Batch transform job started. Results will be stored at: {output_data_path}\")\n",
    "transformer.wait()\n",
    "print(\"Batch transform job completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
