{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 03 - MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "As you move from running individual AI/ML projects to using AI/ML to transform your business at scale, the discipline of ML Operations (MLOps) can help. MLOps refers to a methodology that is built on applying DevOps practices to machine learning workloads. MLOps focuses on the intersection of data science and data engineering in combination with existing DevOps practices to streamline model delivery across the machine learning development lifecycle. ML model building requires many iterations of training as you tune the algorithm, model architecture, and parameters to achieve high prediction accuracy. \n",
    "\n",
    "[Amazon SageMaker AI with MLflow](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html) helps you track, organize, view, analyze, and compare iterative ML experimentation to gain comparative insights and register and deploy your best performing models. You can compare model performance, parameters, and metrics across experiments in the MLflow UI, keep track of your best models in the MLflow Model Registry, automatically register them as a SageMaker AI model, and deploy registered models to SageMaker AI endpoints.\n",
    "\n",
    "This notebook demonstrates how you can use SageMaker AI with MLflow to perform the following:\n",
    "1. Use an MLflow Tracking server to run experiments\n",
    "2. Process data on a SageMaker managed cluster using SageMaker Training jobs\n",
    "3. Train an XGBoost model in a SageMaker managed cluster using SageMaker Training jobs\n",
    "4. Save the model to the SageMaker model registry\n",
    "5. Deploy your model for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Set up environment\n",
    "\n",
    "Restore variables from the `00_setup` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_data_path test_data_path\n",
    "%store -r bucket_name model_prefix model_artifact\n",
    "%store -r role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Import the necessary libraries and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import os\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "prefix = \"mlflow-credit-risk\"\n",
    "\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "s3_root_folder = f\"s3://{bucket_name}/{prefix}\"\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role(sess)\n",
    "print (f\"Your Amazon SageMaker Execution role is: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 2. Locate MLflow Tracking server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Amazon SageMaker AI with MLflow is a capability of Amazon SageMaker AI that lets you create, manage, analyze, and compare your machine learning experiments. We need to set up an [MLflow tracking server](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow-create-tracking-server.html) to track our machine learning (ML) experiments with this capability. An MLflow Tracking Server is a stand-alone HTTP server that serves multiple REST API endpoints for tracking runs and experiments. \n",
    "\n",
    "To set up and manage an MLflow tracking server, as well as work with managed MLflow experiments, we need to add MLflow permissions to the SageMaker execution role. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Add MLflow permissions to SageMaker Execution Role\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Important:</b> Skip this step if you are at an AWS event and using temporary AWS accounts provided by the event organisers.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "- On AWS Console, navigate to IAM, click on Roles on the left hand menu\n",
    "- Type in AmazonSageMaker-ExecutionRole and select the role that matches the SageMaker Execution Role Name retrievd in the previous step\n",
    "- Click \"Add permissions\" then choose \"Create inline policy\"\n",
    "- Switch to JSON editor and paste the following json\n",
    "- Add a name for the policy like, \"MLFlow Permissions\" and follow the next steps to complete creating it. \n",
    "\n",
    "```json\n",
    "{\n",
    "\t\"Version\": \"2012-10-17\",\n",
    "\t\"Statement\": [\n",
    "\t\t{\n",
    "\t\t\t\"Sid\": \"VisualEditor0\",\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Action\": [\n",
    "\t\t\t\t\"sagemaker:DeleteMlflowTrackingServer\",\n",
    "\t\t\t\t\"sagemaker:StartMlflowTrackingServer\",\n",
    "\t\t\t\t\"sagemaker:CreatePresignedMlflowTrackingServerUrl\",\n",
    "\t\t\t\t\"sagemaker:UpdateMlflowTrackingServer\",\n",
    "\t\t\t\t\"sagemaker:CreateMlflowTrackingServer\",\n",
    "\t\t\t\t\"sagemaker:StopMlflowTrackingServer\"\n",
    "\t\t\t],\n",
    "\t\t\t\"Resource\": \"*\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"Sid\": \"VisualEditor1\",\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Action\": [\n",
    "\t\t\t\t\"sagemaker-mlflow:*\"\n",
    "\t\t\t],\n",
    "\t\t\t\"Resource\": \"*\"\n",
    "\t\t}\n",
    "\t]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "The following code reads the SageMaker Studio resource metadata file to identify which domain the notebook is running in. The metadata file at /opt/ml/metadata/resource-metadata.json contains important information about the Studio environment, including the domain identifier. We will use the domain identifier to set-up the MLFlow server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_METADATA_FILE = \"/opt/ml/metadata/resource-metadata.json\"\n",
    "domain_id = 'default'\n",
    "if os.path.exists(NOTEBOOK_METADATA_FILE):\n",
    "    with open(NOTEBOOK_METADATA_FILE, \"rb\") as f:\n",
    "        metadata = json.loads(f.read())\n",
    "        domain_id = metadata.get('DomainId')\n",
    "        space_name = metadata.get('SpaceName')\n",
    "        print(f\"SageMaker domain id: {domain_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Next we want to set-up an MLFlow server to track our experiments. We first look for existing servers in \"Created\" or \"Creating\" states, prioritizing the most recently created ones. If no suitable server is found, we provision a new MLflow tracking server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_running_mlflow_server(sagemaker_client, status_filter=['Created', 'Creating']):\n",
    "    for status in status_filter:\n",
    "        servers = sagemaker_client.list_mlflow_tracking_servers(TrackingServerStatus=status, SortBy='CreationTime', SortOrder='Descending')['TrackingServerSummaries']\n",
    "        if servers:\n",
    "            for server in servers:\n",
    "                print(f\"Found an MLflow server {server['TrackingServerArn']} in the status '{status}'.\")\n",
    "                return server['TrackingServerArn'], server['TrackingServerName']\n",
    "    print(\"No MLflow servers found.\")\n",
    "    return None, None\n",
    "\n",
    "def create_mlflow_server(sagemaker_client, bucket_name, sm_role, domain_id):\n",
    "    \"\"\"\n",
    "    Creates a new MLflow server and returns its ARN and name.\n",
    "    \"\"\"\n",
    "    timestamp = strftime('%d-%H-%M-%S', gmtime())\n",
    "    mlflow_name = f\"mlflow-{domain_id}-{timestamp}\"\n",
    "    response = sagemaker_client.create_mlflow_tracking_server(\n",
    "        TrackingServerName=mlflow_name,\n",
    "        ArtifactStoreUri=f\"s3://{bucket_name}/mlflow/{timestamp}\",\n",
    "        RoleArn=sm_role,\n",
    "        AutomaticModelRegistration=True,\n",
    "    )\n",
    "\n",
    "    mlflow_arn = response['TrackingServerArn']\n",
    "    print(f\"Server creation request succeeded. The server {mlflow_arn} is being created.\")\n",
    "    return mlflow_arn, mlflow_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a running MLflow server \n",
    "mlflow_arn, mlflow_name = get_running_mlflow_server(sagemaker_client)\n",
    "print(f\"Using server {mlflow_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "If you are running this workshop at an AWS event, an MLflow tracking server should already be available. If no tracking server was found in the last step, the following cell with create it for you. Note this can take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new one if none exists\n",
    "\n",
    "if not mlflow_arn:\n",
    "    mlflow_arn, mlflow_name = create_mlflow_server(sagemaker_client, bucket_name, role, domain_id)\n",
    "print(f\"Using server {mlflow_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 3. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "The code was adapted from this repository https://github.com/aws-samples/amazon-sagemaker-credit-risk-prediction-explainability-bias-detection/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "In this step, we'll load our training data from the CSV file that was created during the set-up phase. This file contains the features and target variable that we will use to train our XGBoost model for credit risk prediction. We perform some basic pre-processing and upload the training and test files to Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_columns = [\n",
    "    \"status\",\n",
    "    \"duration\",\n",
    "    \"credit_history\",\n",
    "    \"purpose\",\n",
    "    \"amount\",\n",
    "    \"savings\",\n",
    "    \"employment_duration\",\n",
    "    \"installment_rate\",\n",
    "    \"personal_status_sex\",\n",
    "    \"other_debtors\",\n",
    "    \"present_residence\",\n",
    "    \"property\",\n",
    "    \"age\",\n",
    "    \"other_installment_plans\",\n",
    "    \"housing\",\n",
    "    \"number_credits\",\n",
    "    \"job\",\n",
    "    \"people_liable\",\n",
    "    \"telephone\",\n",
    "    \"foreign_worker\",\n",
    "    \"credit_risk\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\n",
    "    \"data/SouthGermanCredit.asc\",\n",
    "    names=credit_columns,\n",
    "    header=0,\n",
    "    sep=r\" \",\n",
    "    engine=\"python\",\n",
    "    na_values=\"?\",\n",
    ").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = training_data.sample(frac=0.1, random_state=42)\n",
    "test_data = test_data.drop(\"credit_risk\", axis=1)\n",
    "test_columns = [\n",
    "    \"status\",\n",
    "    \"duration\",\n",
    "    \"credit_history\",\n",
    "    \"purpose\",\n",
    "    \"amount\",\n",
    "    \"savings\",\n",
    "    \"employment_duration\",\n",
    "    \"installment_rate\",\n",
    "    \"personal_status_sex\",\n",
    "    \"other_debtors\",\n",
    "    \"present_residence\",\n",
    "    \"property\",\n",
    "    \"age\",\n",
    "    \"other_installment_plans\",\n",
    "    \"housing\",\n",
    "    \"number_credits\",\n",
    "    \"job\",\n",
    "    \"people_liable\",\n",
    "    \"telephone\",\n",
    "    \"foreign_worker\",\n",
    "]\n",
    "\n",
    "training_data.to_csv(\"train.csv\", index=False, header=True, columns=credit_columns)\n",
    "test_data.to_csv(\"test.csv\", index=False, header=True, columns=test_columns)\n",
    "\n",
    "# save the datasets in S3 for future use\n",
    "train_s3_url = sagemaker.Session().upload_data(\n",
    "    path=\"train.csv\",\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=f\"{prefix}/input\"\n",
    ")\n",
    "print(f\"Upload the dataset to {train_s3_url}\")\n",
    "\n",
    "test_s3_url = sagemaker.Session().upload_data(\n",
    "    path=\"test.csv\",\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=f\"{prefix}/input\"\n",
    ")\n",
    "print(f\"Upload the dataset to {test_s3_url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing with SageMaker Remote Functions and MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Next, we define a ***process*** method that prepares our credit risk data for machine learning. This method does the following to get our data ready for XGBoost:\n",
    "- It performs one-hot encoding of categorical features and splits data into training and validation sets\n",
    "- It logs parameters and artifacts to MLflow, and saves the preprocessed datasets\n",
    "- The featurizer model is also serialized and stored as a model artifact, enabling consistent feature transformation during inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Note the use of the **@remote** decorator. This decorator starts a training job that allows the preprocessing function to execute on a separate SageMaker instance (ml.m5.large), offloading resource-intensive operations from the notebook environment. This approach combines the scalability of SageMaker with the experiment tracking capabilities of MLflow to create a reproducible and well-documented machine learning workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "experiment_suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "registered_model_name = f\"credit-risk-model-{experiment_suffix}\"\n",
    "experiment_name = f\"credit-risk-model-experiment-{experiment_suffix}\"\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import sklearn\n",
    "import joblib\n",
    "import mlflow\n",
    "from sagemaker.s3 import S3Uploader\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sagemaker.remote_function import remote\n",
    "\n",
    "\n",
    "@remote(s3_root_uri=f\"s3://{bucket_name}/{prefix}\", dependencies=f\"requirements.txt\", instance_type=\"ml.m5.large\")\n",
    "def preprocess(df, experiment_name, mlflow_arn, bucket_name, prefix, run_id=None):\n",
    "    \"\"\"\n",
    "    Preprocess the input data and split it into training and validation sets.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input data.\n",
    "        experiment_name (str): Name of the MLflow experiment.\n",
    "        run_id (str, optional): MLflow run ID. If not provided, a new run will be created.\n",
    "        mlflow_arn (str, optional): MLflow tracking URI.\n",
    "        s3_root_folder (str, optional): S3 root folder for remote execution.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training and validation features and labels.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(mlflow_arn)\n",
    "        suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "        mlflow.set_experiment(experiment_name=experiment_name if experiment_name else f\"credit-risk-model-experiment-{suffix}\")\n",
    "        run = mlflow.start_run(run_id=run_id) if run_id else mlflow.start_run(run_name=f\"remote-processing-{suffix}\", nested=True)\n",
    "\n",
    "        output_path = \"/opt/ml/output/data\"\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "        print(\"Reading input data\")\n",
    "        model_dataset = mlflow.data.from_pandas(df)\n",
    "        mlflow.log_input(model_dataset, context=\"model_dataset\")\n",
    "\n",
    "        print(\"Performing one-hot encoding\")\n",
    "        categorical_cols = [\n",
    "            \"credit_history\",\n",
    "            \"purpose\",\n",
    "            \"personal_status_sex\",\n",
    "            \"other_debtors\",\n",
    "            \"property\",\n",
    "            \"other_installment_plans\",\n",
    "            \"housing\",\n",
    "            \"job\",\n",
    "            \"telephone\",\n",
    "            \"foreign_worker\",\n",
    "        ]\n",
    "        transformer = make_column_transformer(\n",
    "            (OneHotEncoder(sparse_output=False), categorical_cols),\n",
    "            remainder=\"passthrough\",\n",
    "        )\n",
    "\n",
    "        print(\"Preparing features and labels\")\n",
    "        X = df.drop(\"credit_risk\", axis=1)\n",
    "        y = df[\"credit_risk\"]\n",
    "\n",
    "        print(\"Building scikit-learn transformer\")\n",
    "        featurizer_model = transformer.fit(X)\n",
    "        features = featurizer_model.transform(X)\n",
    "        labels = LabelEncoder().fit_transform(y)\n",
    "\n",
    "        split_ratio = 0.3\n",
    "        print(f\"Splitting data into train and validation sets with ratio {split_ratio}\")\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            features, labels, test_size=split_ratio, random_state=0\n",
    "        )\n",
    "\n",
    "        print(f\"Train features shape after preprocessing: {X_train.shape}\")\n",
    "        print(f\"Validation features shape after preprocessing: {X_val.shape}\")\n",
    "\n",
    "        mlflow.log_params({\"train_shape\": X_train.shape, \"val_shape\": X_val.shape})\n",
    "\n",
    "        train_features_path = os.path.join(output_path, \"train_features.csv\")\n",
    "        print(f\"Saving training features to {train_features_path}\")\n",
    "        pd.DataFrame(X_train).to_csv(train_features_path, header=False, index=False)\n",
    "\n",
    "        train_labels_path = os.path.join(output_path, \"train_labels.csv\")\n",
    "        print(f\"Saving training labels to {train_labels_path}\")\n",
    "        pd.DataFrame(y_train).to_csv(train_labels_path, header=False, index=False)\n",
    "\n",
    "        val_features_path = os.path.join(output_path, \"val_features.csv\")\n",
    "        print(f\"Saving validation features to {val_features_path}\")\n",
    "        pd.DataFrame(X_val).to_csv(val_features_path, header=False, index=False)\n",
    "\n",
    "        val_labels_path = os.path.join(output_path, \"val_labels.csv\")\n",
    "        print(f\"Saving validation labels to {val_labels_path}\")\n",
    "        pd.DataFrame(y_val).to_csv(val_labels_path, header=False, index=False)\n",
    "\n",
    "        model_dir = \"/opt/ml/model\"\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        model_path = os.path.join(model_dir, \"model.joblib\")\n",
    "        model_output_path = os.path.join(model_dir, \"model.tar.gz\")\n",
    "\n",
    "        print(f\"Saving featurizer model to {model_output_path}\")\n",
    "        joblib.dump(featurizer_model, model_path)\n",
    "        with tarfile.open(model_output_path, \"w:gz\") as tar:\n",
    "            tar.add(model_path, arcname=\"model.joblib\")\n",
    "\n",
    "        logged_model = mlflow.sklearn.log_model(\n",
    "            sk_model=featurizer_model,\n",
    "            artifact_path=\"processing/model\",\n",
    "            registered_model_name=\"sk-learn-model\",\n",
    "        )\n",
    "        return X_train, X_val, y_train, y_val, logged_model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in processing script: {e}\")\n",
    "        raise e\n",
    "    finally:\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input/train_data.csv\", names=None, header=0, sep=\",\")\n",
    "X_train, X_val, y_train, y_val, logged_featurizer_model = preprocess(df, experiment_name, mlflow_arn, bucket_name, prefix)\n",
    "print(logged_featurizer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_featurizer_model.model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## 5. Model training with SageMaker training jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "In this step we define a function that trains an XGBoost model for credit risk prediction, saves it and registers it in MLflow for version control.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import mlflow\n",
    "import tarfile\n",
    "\n",
    "@remote(s3_root_uri=f\"s3://{bucket_name}/{prefix}\", dependencies=f\"requirements.txt\", instance_type=\"ml.m5.large\")\n",
    "def train(X, val_X, y, val_y, num_round, params, mlflow_arn, experiment_name,run_id=None):\n",
    "    output_path = \"/opt/ml/model\"\n",
    "    mlflow.set_tracking_uri(mlflow_arn)\n",
    "    mlflow.autolog()\n",
    "    \n",
    "    suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "    mlflow.set_experiment(experiment_name=experiment_name if experiment_name else f\"credit-risk-model-experiment-{suffix}\")\n",
    "    run = mlflow.start_run(run_id=run_id) if run_id else mlflow.start_run(run_name=f\"remote-training-{suffix}\", nested=True)\n",
    "\n",
    "    try:\n",
    "        os.makedirs(output_path, exist_ok=True)\n",
    "        print(f\"Directory '{output_path}' created successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error creating directory '{output_path}': {e}\")\n",
    "        \n",
    "    dtrain = xgboost.DMatrix(X, label=y)\n",
    "    dval = xgboost.DMatrix(val_X, label=val_y)\n",
    "\n",
    "    dtrain = xgboost.DMatrix(X, label=y)\n",
    "    dval = xgboost.DMatrix(val_X, label=val_y)\n",
    "\n",
    "    watchlist = [(dtrain, \"train\"), (dval, \"validation\")]\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    print(\"Training the model\")\n",
    "    evaluation__results = {}\n",
    "    bst = xgboost.train(\n",
    "        params=params, dtrain=dtrain, evals=watchlist, num_boost_round=num_round\n",
    "    )\n",
    "    bst.save_model(output_path + \"/model.ubj\")\n",
    "\n",
    "     # Compress the model.bin artifact to a tar file\n",
    "    tar_filename = f\"{output_path}/model.tar.gz\"\n",
    "    with tarfile.open(tar_filename, \"w:gz\") as tar:\n",
    "        tar.add(f\"{output_path}/model.bin\", arcname=\"model.ubj\")\n",
    "\n",
    "    mlflow.log_artifact(local_path=tar_filename)\n",
    "\n",
    "    logged_model = mlflow.xgboost.log_model(\n",
    "        xgb_model=bst,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"xgb-creditrisk-model\"\n",
    "    )  \n",
    "    return logged_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.1\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"silent\": \"1\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"100\",\n",
    "    \"subsample\": \"0.8\",\n",
    "    \"eval_metric\": \"auc\"\n",
    "}\n",
    "num_round = 50\n",
    "\n",
    "logged_creditrisk_model = train(X_train, X_val, y_train, y_val,num_round, hyperparameters, mlflow_arn, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_creditrisk_model.model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2655b8c",
   "metadata": {},
   "source": [
    "We will store the following variables that will be used in the optional challenge section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c132bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store mlflow_arn\n",
    "%store experiment_name\n",
    "%store logged_featurizer_model\n",
    "%store logged_creditrisk_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## 6. Register your candidate model directly with the SageMaker model registry (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "In the previous sections, the trained featurizer and credit risk models were registered in the MLflow model registry. The models were also automatically registered in the SageMaker model registry.\n",
    "\n",
    "In this module you will see how you can also register models directly with the SageMaker Model Registry. This option can be used if you do not want to use MLFlow, and also supports some additional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(mlflow_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Next, we filter MLflow training runs to identify the best performing model using validation AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import ViewType\n",
    "\n",
    "run_filter = f\"\"\"\n",
    "attributes.run_name LIKE \"%training%\"\n",
    "attributes.status = 'FINISHED'\n",
    "\"\"\"\n",
    "\n",
    "runs_with_filter = mlflow.search_runs(\n",
    "    experiment_names=[experiment_name],\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    filter_string=run_filter,\n",
    "    order_by=[\"metrics.`validation-auc` DESC\"],\n",
    ")\n",
    "best_run = runs_with_filter[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_uri = best_run['artifact_uri'][0]\n",
    "print(artifact_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "[SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-models.html) is structured as several Model (Package) Groups with model packages in each group. A model package is the actual model that is registered into the Model Registry as a versioned entity. The Model Registry receives every new model that you retrain, gives it a version, and assigns it to a Model Group inside the Model Registry. The model \n",
    "\n",
    "In the next steps, we create a new model package and assign it to a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker_client.list_model_package_groups()\n",
    "model_package_group_arn = response['ModelPackageGroupSummaryList'][0]['ModelPackageGroupArn']\n",
    "print(model_package_group_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{artifact_uri}/model/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "modelpackage_inference_specification =  {\n",
    "    \"InferenceSpecification\": {\n",
    "      \"Containers\": [\n",
    "         {\n",
    "            \"Image\": \"public.ecr.aws/sagemaker/sagemaker-distribution:3.0.0-cpu\",\n",
    "    \t    \"ModelDataUrl\": f\"{artifact_uri}/model.tar.gz\"\n",
    "         }\n",
    "      ],\n",
    "      \"SupportedContentTypes\": [ \"text/csv\" ],\n",
    "      \"SupportedResponseMIMETypes\": [ \"text/csv\" ],\n",
    "   },\n",
    "    \"ModelPackageGroupName\" : model_package_group_arn,\n",
    "    \"ModelPackageDescription\" : \"Model to detect credit risk\",\n",
    "    \"ModelApprovalStatus\" : \"PendingManualApproval\"\n",
    "}\n",
    "\n",
    "model_package_group_name = \"model-group-\" + str(round(time.time()))\n",
    "\n",
    "create_model_package_input_dict = {\n",
    "    \"ModelPackageGroupName\" : model_package_group_name,\n",
    "    \"ModelPackageDescription\" : \"Model to detect credit risk\",\n",
    "    \"ModelApprovalStatus\" : \"PendingManualApproval\"\n",
    "}\n",
    "create_model_package_input_dict.update(modelpackage_inference_specification)\n",
    "\n",
    "create_model_package_response = sagemaker_client.create_model_package(**create_model_package_input_dict)\n",
    "model_package_arn = create_model_package_response[\"ModelPackageArn\"]\n",
    "print('ModelPackage Version ARN : {}'.format(model_package_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### Conclusion and Next Steps:\n",
    "In this notebook, \n",
    "- You set up an MLflow tracking server\n",
    "- Preprocessed data using SageMaker Remote Functions and MLflow\n",
    "- Trained an XGBoost model for credit risk prediction\n",
    "- Saved a model package to a Model Group in SageMaker Model Registry \n",
    "\n",
    "Now, if you're up for a challenge move on to the notebook 04_challenge!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
